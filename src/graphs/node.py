import os
import re
import zipfile
import shutil
from typing import List, Dict, Any
from langchain_core.runnables import RunnableConfig
from langgraph.runtime import Runtime
from coze_coding_utils.runtime_ctx.context import Context
from graphs.state import (
    AnalyzeStructureInput,
    AnalyzeStructureOutput,
    ExtractFunctionsInput,
    ExtractFunctionsOutput,
    AnalyzeCallRelationInput,
    AnalyzeCallRelationOutput,
    GenerateFlowchartInput,
    GenerateFlowchartOutput,
    GenerateReadmeInput,
    GenerateReadmeOutput,
    UnzipInput,
    UnzipOutput,
    UploadLocalFileInput,
    UploadLocalFileOutput,
)
import json
from jinja2 import Template


def upload_local_file_node(state: UploadLocalFileInput, config: RunnableConfig, runtime: Runtime[Context]) -> UploadLocalFileOutput:
    """
    title: ä¸Šä¼ æœ¬åœ°æ–‡ä»¶
    desc: å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨ï¼›å¦‚æœæ˜¯URLæˆ–ç›®å½•ï¼Œç›´æ¥è¿”å›
    integrations: å¯¹è±¡å­˜å‚¨
    """

    path = state.component_path.strip()  # å»é™¤å‰åç©ºæ ¼

    # æ£€æµ‹Windowsè·¯å¾„æ ¼å¼ï¼ˆD:/ æˆ– C:\ ç­‰ï¼‰
    if re.match(r'^[A-Za-z]:[/\\]', path):
        error_msg = f"""
âŒ æ£€æµ‹åˆ°Windowsè·¯å¾„æ ¼å¼ï¼Œæ— æ³•åœ¨Linuxç¯å¢ƒä¸­è®¿é—®ï¼
è·¯å¾„: {path}

è§£å†³æ–¹æ¡ˆï¼š
1. å¦‚æœåœ¨WSLä¸­ï¼Œè¯·ä½¿ç”¨Linuxè·¯å¾„æ ¼å¼ï¼š
   Windows: D:/wsl-file-sharing/file.zip
   WSLè·¯å¾„: /mnt/d/wsl-file-sharing/file.zip

2. å¦‚æœæ–‡ä»¶åœ¨Windowsä¸Šï¼Œè¯·ï¼š
   - å¤åˆ¶æ–‡ä»¶åˆ°Linuxå¯è®¿é—®çš„ç›®å½•
   - æˆ–ä½¿ç”¨å¯¹è±¡å­˜å‚¨URL

3. å¦‚æœä½¿ç”¨WSLï¼Œæ­£ç¡®çš„è·¯å¾„åº”è¯¥æ˜¯ï¼š
   /mnt/d/wsl-file-sharing/newbridge/robotics_svc_media.zip
        """
        raise Exception(error_msg.strip())

    # å¦‚æœæ˜¯URLï¼Œç›´æ¥è¿”å›
    if path.startswith('http://') or path.startswith('https://'):
        return UploadLocalFileOutput(zip_file_path=path)

    # å¦‚æœæ˜¯ç›®å½•ï¼Œç›´æ¥è¿”å›
    if os.path.isdir(path):
        return UploadLocalFileOutput(zip_file_path=path)

    # å¦‚æœæ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨ï¼ˆä»…åœ¨Cozeç¯å¢ƒä¸­ï¼‰
    if os.path.isfile(path):
        # æ£€æŸ¥æ˜¯å¦åœ¨Cozeç¯å¢ƒä¸­ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡åˆ¤æ–­ï¼‰
        in_coze_env = os.getenv('COZE_WORKSPACE_PATH') and (
            os.getenv('COZE_BUCKET_ENDPOINT_URL') or os.getenv('COZE_BUCKET_NAME')
        )

        if in_coze_env:
            try:
                from coze_coding_dev_sdk.s3 import S3SyncStorage
                import os as env_os

                # åˆå§‹åŒ–å¯¹è±¡å­˜å‚¨
                storage = S3SyncStorage(
                    endpoint_url=env_os.getenv("COZE_BUCKET_ENDPOINT_URL"),
                    access_key="",
                    secret_key="",
                    bucket_name=env_os.getenv("COZE_BUCKET_NAME"),
                    region="cn-beijing",
                )

                # è¯»å–æ–‡ä»¶
                filename = os.path.basename(path)
                with open(path, 'rb') as f:
                    file_content = f.read()

                # ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨
                file_key = storage.upload_file(
                    file_content=file_content,
                    file_name=filename,
                    content_type="application/zip" if filename.endswith('.zip') else "application/octet-stream",
                )

                # ç”Ÿæˆä¸‹è½½URL
                download_url = storage.generate_presigned_url(key=file_key, expire_time=3600)

                print(f"âœ… æ–‡ä»¶å·²ä¸Šä¼ åˆ°å¯¹è±¡å­˜å‚¨: {file_key}")
                print(f"ğŸ“¥ ä¸‹è½½URL: {download_url}")

                return UploadLocalFileOutput(zip_file_path=download_url)

            except Exception as e:
                print(f"âš ï¸ ä¸Šä¼ å¯¹è±¡å­˜å‚¨å¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°è·¯å¾„: {str(e)}")
                # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œè¿”å›æœ¬åœ°è·¯å¾„
                return UploadLocalFileOutput(zip_file_path=path)
        else:
            # æœ¬åœ°ç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
            print(f"ğŸ“ æœ¬åœ°è¿è¡Œæ¨¡å¼ï¼Œä½¿ç”¨æœ¬åœ°æ–‡ä»¶è·¯å¾„: {path}")
            return UploadLocalFileOutput(zip_file_path=path)

    raise Exception(f"âŒ è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨: {path}\n\nè¯·æ£€æŸ¥ï¼š\n1. è·¯å¾„æ˜¯å¦æ­£ç¡®\n2. æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n3. æ˜¯å¦ä½¿ç”¨äº†Windowsè·¯å¾„æ ¼å¼ï¼ˆåº”ä½¿ç”¨Linuxè·¯å¾„ï¼‰")


def unzip_node(state: UnzipInput, config: RunnableConfig, runtime: Runtime[Context]) -> UnzipOutput:
    """
    title: è§£å‹ç¼©æ–‡ä»¶
    desc: å¦‚æœè¾“å…¥æ˜¯zipæ–‡ä»¶ï¼Œåˆ™è§£å‹åˆ°ä¸´æ—¶ç›®å½•ï¼›å¦‚æœæ˜¯æ–‡ä»¶å¤¹ï¼Œç›´æ¥è¿”å›
    """

    path = state.zip_file_path

    # åˆ¤æ–­æ˜¯å¦æ˜¯URL
    is_url = path.startswith('http://') or path.startswith('https://')

    # åˆ¤æ–­æ˜¯å¦æ˜¯zipæ–‡ä»¶ï¼ˆå¯¹äºURLï¼Œæ£€æŸ¥è·¯å¾„éƒ¨åˆ†ï¼‰
    if is_url or path.endswith('.zip') or path.endswith('.ZIP'):
        # å¦‚æœæ˜¯URLï¼Œå…ˆä¸‹è½½åˆ°ä¸´æ—¶æ–‡ä»¶
        if is_url:
            from urllib.parse import urlparse
            import tempfile

            # è§£æURLè·å–æ–‡ä»¶å
            parsed_url = urlparse(path)
            filename = os.path.basename(parsed_url.path)

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
            temp_file.close()

            try:
                import requests
                response = requests.get(path, timeout=120)
                response.raise_for_status()

                with open(temp_file.name, 'wb') as f:
                    f.write(response.content)

                print(f"å·²ä¸‹è½½åˆ°: {temp_file.name}")
                path = temp_file.name
            except Exception as e:
                os.unlink(temp_file.name)
                raise Exception(f"ä¸‹è½½å¤±è´¥: {str(e)}")

        # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
        import tempfile
        temp_dir = tempfile.mkdtemp(prefix="component_extracted_")

        try:
            with zipfile.ZipFile(path, 'r') as zip_ref:
                zip_ref.extractall(temp_dir)

            print(f"å·²è§£å‹åˆ°: {temp_dir}")

            # å¦‚æœæ˜¯ä¸‹è½½çš„ä¸´æ—¶æ–‡ä»¶ï¼Œåˆ é™¤å®ƒ
            if is_url and 'temp_file' in locals():
                os.unlink(temp_file.name)

            # æå–ç»„ä»¶åç§°ï¼ˆä»è§£å‹åçš„ç¬¬ä¸€ä¸ªå­æ–‡ä»¶å¤¹ï¼‰
            component_name = "Unknown"
            try:
                items = os.listdir(temp_dir)
                if items:
                    # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶å¤¹ä½œä¸ºç»„ä»¶åç§°
                    first_item = items[0]
                    if os.path.isdir(os.path.join(temp_dir, first_item)):
                        component_name = first_item
            except Exception:
                component_name = "Component"

            print(f"ç»„ä»¶åç§°: {component_name}")

            # è¿”å›è§£å‹åçš„è·¯å¾„å’Œç»„ä»¶åç§°
            return UnzipOutput(extracted_path=temp_dir, component_name=component_name)
        except Exception as e:
            shutil.rmtree(temp_dir, ignore_errors=True)
            raise Exception(f"è§£å‹å¤±è´¥: {str(e)}")
    else:
        # å¦‚æœä¸æ˜¯zipæ–‡ä»¶ï¼Œç›´æ¥è¿”å›åŸè·¯å¾„
        if os.path.isdir(path):
            # æå–ç»„ä»¶åç§°
            component_name = os.path.basename(path.rstrip('/'))
            print(f"ç»„ä»¶åç§°: {component_name}")
            return UnzipOutput(extracted_path=path, component_name=component_name)
        else:
            raise Exception(f"è·¯å¾„æ—¢ä¸æ˜¯zipæ–‡ä»¶ä¹Ÿä¸æ˜¯ç›®å½•: {path}")


def analyze_structure_node(state: AnalyzeStructureInput, config: RunnableConfig, runtime: Runtime[Context]) -> AnalyzeStructureOutput:
    """
    title: æ–‡ä»¶å¤¹ç»“æ„åˆ†æ
    desc: åˆ†æç»„ä»¶æ–‡ä»¶å¤¹çš„å±‚çº§ç»“æ„ï¼Œè¯†åˆ«å¼€æºä»£ç åº“ï¼Œè¾“å‡ºæ ‘çŠ¶ç»“æ„
    """

    component_path = state.extracted_path

    # æ˜ç¡®çš„ç¬¬ä¸‰æ–¹åº“/å¼€æºä»£ç æ–‡ä»¶å¤¹åç§°
    OPENSOURCE_FOLDER_NAMES = [
        'opencv', 'opencv_contrib', 'opencv_extra',
        'tensorflow', 'tensorflow_cc', 'tensorflow_lite',
        'pytorch', 'torch', 'caffe', 'mxnet',
        'vendor', 'vendors', 'third_party', '3rdparty', 'external',
        'libs', 'lib', 'dependencies', 'deps',
        'build', 'cmake-build', 'out', 'bin',
    ]

    # å¯èƒ½è¡¨ç¤ºç¬¬ä¸‰æ–¹åº“çš„ç‰¹å¾æ–‡ä»¶ï¼ˆä»…åœ¨æ ¹çº§åˆ«æ—¶æ‰è®¤ä¸ºæ˜¯å¼€æºåº“ï¼‰
    OPENSOURCE_MARKERS = [
        '.git',
    ]

    def is_opensource_folder(folder_path: str, folder_name: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºå¼€æºä»£ç åº“æ–‡ä»¶å¤¹"""
        if not os.path.isdir(folder_path):
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦åŒ¹é…å·²çŸ¥çš„ç¬¬ä¸‰æ–¹åº“åç§°
        if folder_name.lower() in [name.lower() for name in OPENSOURCE_FOLDER_NAMES]:
            return True

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨.gitæ–‡ä»¶å¤¹ï¼ˆæ˜ç¡®çš„ç‰ˆæœ¬æ§åˆ¶æ ‡è®°ï¼‰
        git_folder = os.path.join(folder_path, '.git')
        if os.path.exists(git_folder) and os.path.isdir(git_folder):
            return True

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ LICENSE æ–‡ä»¶ï¼ˆä»…å½“æ ¹ç›®å½•æœ‰æ­¤æ–‡ä»¶æ—¶æ‰è®¤ä¸ºæ˜¯å¼€æºåº“ï¼‰
        # æ³¨æ„ï¼šREADME.md å¾ˆå¸¸è§ï¼Œä¸åº”è¯¥ä½œä¸ºåˆ¤æ–­ä¾æ®
        license_markers = ['LICENSE', 'LICENSE.txt', 'LICENSE.md', 'LICENSE.MIT',
                          'COPYING', 'COPYRIGHT']
        items = os.listdir(folder_path)
        for marker in license_markers:
            if marker in items:
                return True

        return False

    def get_folder_comment(folder_name: str, path: str) -> str:
        """æ ¹æ®æ–‡ä»¶å¤¹åç§°ç”Ÿæˆæ³¨é‡Šè¯´æ˜"""
        folder_lower = folder_name.lower()

        # å¸¸è§æ–‡ä»¶å¤¹çš„æ³¨é‡Š
        comments = {
            'include': '# å…¬å…± API å¤´æ–‡ä»¶',
            'src': '# å®ç°æ–‡ä»¶',
            'lib': '# ç¬¬ä¸‰æ–¹åº“',
            'libs': '# ç¬¬ä¸‰æ–¹åº“',
            'vendor': '# ç¬¬ä¸‰æ–¹ä¾èµ–',
            'third_party': '# ç¬¬ä¸‰æ–¹ä¾èµ–',
            'build': '# æ„å»ºè¾“å‡ºç›®å½•',
            'cmake-build': '# CMake æ„å»ºè¾“å‡º',
            'output': '# è¾“å‡ºç›®å½•',
            'bin': '# å¯æ‰§è¡Œæ–‡ä»¶',
            'docs': '# æ–‡æ¡£',
            'doc': '# æ–‡æ¡£',
            'examples': '# ç¤ºä¾‹ä»£ç ',
            'example': '# ç¤ºä¾‹ä»£ç ',
            'tests': '# æµ‹è¯•ä»£ç ',
            'test': '# æµ‹è¯•ä»£ç ',
            'tools': '# å·¥å…·è„šæœ¬',
            'scripts': '# è„šæœ¬æ–‡ä»¶',
            'config': '# é…ç½®æ–‡ä»¶',
            'configs': '# é…ç½®æ–‡ä»¶',
            'resources': '# èµ„æºæ–‡ä»¶',
            'assets': '# èµ„æºæ–‡ä»¶',
            'model': '# æ¨¡å‹æ–‡ä»¶',
            'models': '# æ¨¡å‹æ–‡ä»¶',
            'data': '# æ•°æ®æ–‡ä»¶',
            'input': '# è¾“å…¥æ•°æ®',
            'output': '# è¾“å‡ºæ•°æ®',
            'opencv': '# OpenCV åº“',
            'tensorflow': '# TensorFlow åº“',
            'pytorch': '# PyTorch åº“',
            'torch': '# PyTorch åº“',
            '.git': '# Git ç‰ˆæœ¬æ§åˆ¶',
            'github': '# GitHub ç›¸å…³æ–‡ä»¶',
        }

        return comments.get(folder_lower, '')

    def analyze_directory(path: str, prefix: str = "", is_last: bool = True) -> str:
        """é€’å½’åˆ†æç›®å½•ç»“æ„ï¼Œç”Ÿæˆæ ‘çŠ¶ç»“æ„"""
        lines = []

        try:
            items = sorted(os.listdir(path))

            # åˆ†ç¦»æ–‡ä»¶å¤¹å’Œæ–‡ä»¶
            dirs = []
            files = []
            for item in items:
                full_path = os.path.join(path, item)

                # è·³è¿‡éšè—æ–‡ä»¶ï¼ˆ.git, .gitignore ç­‰é™¤å¤–ï¼Œç”¨äºè¯†åˆ«å¼€æºä»£ç ï¼‰
                if item.startswith('.') and item not in ['.git', '.gitignore', '.gitmodules']:
                    continue

                if os.path.isdir(full_path):
                    dirs.append(item)
                else:
                    files.append(item)

            # åˆå¹¶æ’åºï¼Œæ–‡ä»¶å¤¹åœ¨å‰
            all_items = dirs + files
            total = len(all_items)

            for idx, item in enumerate(all_items):
                full_path = os.path.join(path, item)
                is_last_item = (idx == total - 1)

                # è®¡ç®—å½“å‰è¡Œçš„å‰ç¼€å’Œå­é¡¹çš„å‰ç¼€
                if is_last:
                    current_prefix = prefix + "â””â”€â”€ "
                    child_prefix = prefix + "    "
                else:
                    current_prefix = prefix + "â”œâ”€â”€ "
                    child_prefix = prefix + "â”‚   "

                if os.path.isdir(full_path):
                    # æ£€æŸ¥æ˜¯å¦ä¸ºå¼€æºä»£ç åº“
                    if is_opensource_folder(full_path, item):
                        comment = "# [ç¬¬ä¸‰æ–¹åº“ï¼Œç•¥è¿‡è¯¦ç»†è¯´æ˜]"
                    else:
                        comment = get_folder_comment(item, full_path)

                    base_text = current_prefix + item + "/"
                    if comment:
                        # è®¡ç®—å¯¹é½ç©ºæ ¼æ•°ï¼Œç›®æ ‡å¯¹é½åˆ°ç¬¬40åˆ—
                        current_length = len(base_text)
                        target_column = 40
                        spaces = max(target_column - current_length, 1)
                        line = base_text + " " * spaces + comment
                    else:
                        line = base_text
                    lines.append(line)

                    # é€’å½’åˆ†æå­æ–‡ä»¶å¤¹ï¼ˆç¬¬ä¸‰æ–¹åº“ä¸å†æ·±å…¥ï¼‰
                    if not is_opensource_folder(full_path, item):
                        sub_content = analyze_directory(full_path, child_prefix, is_last_item)
                        if sub_content:
                            lines.append(sub_content)
                else:
                    # æ–‡ä»¶å¤„ç†
                    # ç‰¹åˆ«å…³æ³¨ .h å’Œ .c/.cpp æ–‡ä»¶
                    if item.endswith('.h') or item.endswith('.hpp'):
                        base_text = current_prefix + item
                        comment = "# å¤´æ–‡ä»¶"
                    elif item.endswith('.c') or item.endswith('.cpp') or item.endswith('.cc'):
                        base_text = current_prefix + item
                        comment = "# æºæ–‡ä»¶"
                    else:
                        base_text = current_prefix + item
                        comment = ""

                    # è®¡ç®—å¯¹é½ç©ºæ ¼æ•°ï¼Œç›®æ ‡å¯¹é½åˆ°ç¬¬40åˆ—
                    if comment:
                        current_length = len(base_text)
                        target_column = 40
                        spaces = max(target_column - current_length, 1)
                        line = base_text + " " * spaces + comment
                    else:
                        line = base_text
                    lines.append(line)

        except Exception as e:
            lines.append(f"{prefix}âŒ æ— æ³•è®¿é—®: {str(e)}")

        return "\n".join(lines)

    # å¼€å§‹åˆ†æ
    if os.path.exists(component_path):
        # è·å–æ ¹ç›®å½•åç§°
        root_name = os.path.basename(component_path.rstrip('/'))

        result_lines = []
        result_lines.append("## ç›®å½•ç»“æ„")
        result_lines.append("")
        result_lines.append("```")
        result_lines.append(f"{root_name}/")
        result_lines.append(analyze_directory(component_path, "", False))
        result_lines.append("```")
        result_lines.append("")

        folder_structure = "\n".join(result_lines)
    else:
        folder_structure = f"âŒ ç»„ä»¶è·¯å¾„ä¸å­˜åœ¨: {component_path}"

    return AnalyzeStructureOutput(folder_structure=folder_structure)


def extract_functions_node(state: ExtractFunctionsInput, config: RunnableConfig, runtime: Runtime[Context]) -> ExtractFunctionsOutput:
    """
    title: å¤´æ–‡ä»¶å‡½æ•°æå–
    desc: æå–includeæ–‡ä»¶å¤¹ä¸‹.hå†…éƒ¨çš„æ‰€æœ‰å‡½æ•°ï¼Œç»“åˆå¤´æ–‡ä»¶æ³¨é‡Šå’Œå¤§æ¨¡å‹åˆ†æï¼Œè¯¦ç»†è¯´æ˜å‡½æ•°åŠŸèƒ½ã€è¾“å…¥å‚æ•°ã€è¿”å›å€¼ã€è°ƒç”¨ç¤ºä¾‹
    integrations: å¤§è¯­è¨€æ¨¡å‹
    """

    component_path = state.extracted_path
    component_name = state.component_name
    ctx = runtime.context

    # æŸ¥æ‰¾ include æ–‡ä»¶å¤¹ï¼ˆæ”¯æŒå¤šå±‚åµŒå¥—ï¼‰
    include_path = None
    for root, dirs, files in os.walk(component_path):
        if 'include' in dirs:
            include_path = os.path.join(root, 'include')
            break

    if not include_path or not os.path.exists(include_path):
        return ExtractFunctionsOutput(header_functions=f"âŒ æœªæ‰¾åˆ° include æ–‡ä»¶å¤¹äº {component_path}")

    # æ”¶é›†æ‰€æœ‰å¤´æ–‡ä»¶å’Œæºæ–‡ä»¶å†…å®¹
    header_content = []
    source_content = []

    include_parent = os.path.dirname(include_path)
    for root, dirs, files in os.walk(component_path):
        for file in files:
            file_path = os.path.join(root, file)
            relative_path = os.path.relpath(file_path, component_path)

            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()

                if file.endswith('.h'):
                    header_content.append(f"\n// File: {relative_path}\n{content}\n")
                elif file.endswith('.c') or file.endswith('.cpp'):
                    source_content.append(f"\n// File: {relative_path}\n{content}\n")
            except Exception as e:
                pass

    # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æå‡½æ•°
    all_code = "\n".join(header_content + source_content)

    # è¯»å–é…ç½®æ–‡ä»¶
    cfg_file = os.path.join(os.getenv("COZE_WORKSPACE_PATH"), config['metadata']['llm_cfg'])
    with open(cfg_file, 'r') as fd:
        _cfg = json.load(fd)

    llm_config = _cfg.get("config", {})
    sp = _cfg.get("sp", "")
    up = _cfg.get("up", "")

    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯Cè¯­è¨€ä»£ç åˆ†æä¸“å®¶ï¼Œè´Ÿè´£åˆ†æå¤´æ–‡ä»¶ä¸­çš„å‡½æ•°å®šä¹‰ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºå‡½æ•°è¯´æ˜ï¼Œä½¿ç”¨Markdownæ ¼å¼ï¼š

```markdown
### é…ç½®ç›¸å…³

#### `config_function_name()`
è·å–æˆ–è®¾ç½®é…ç½®å‚æ•°ã€‚

**å‚æ•°ï¼š**
- `param1`: å‚æ•°1è¯´æ˜
- `param2`: å‚æ•°2è¯´æ˜ï¼ˆå¯é€‰ï¼‰

**è¿”å›å€¼ï¼š** è¿”å›å€¼è¯´æ˜

**ç¤ºä¾‹ï¼š**
```c
// ç¤ºä¾‹ä»£ç 
config_type config = config_function_name();
```

### åˆå§‹åŒ–ä¸æ¸…ç†

#### `init_function_name()`
åˆå§‹åŒ–ç»„ä»¶ã€‚

**å‚æ•°ï¼š**
- `param1`: å‚æ•°1è¯´æ˜

**è¿”å›å€¼ï¼š** 0 æˆåŠŸï¼Œè´Ÿæ•°è¡¨ç¤ºå¤±è´¥

**ç¤ºä¾‹ï¼š**
```c
if (init_function_name(param) != 0) {
    printf("Init failed\\n");
}
```

### æ ¸å¿ƒåŠŸèƒ½

#### `process_function_name()`
æ‰§è¡Œæ ¸å¿ƒå¤„ç†é€»è¾‘ã€‚

**å‚æ•°ï¼š**
- `input`: è¾“å…¥æ•°æ®
- `output`: è¾“å‡ºç¼“å†²åŒº

**è¿”å›å€¼ï¼š** å¤„ç†ç»“æœçŠ¶æ€ç 

**ç¤ºä¾‹ï¼š**
```c
result = process_function_name(input, output);
```
```

æ³¨æ„äº‹é¡¹ï¼š
1. **ä¼˜å…ˆä»includeæ–‡ä»¶å¤¹ä¸‹çš„å…¬å…±APIå¤´æ–‡ä»¶ä¸­æå–å‡½æ•°å£°æ˜å’Œæ³¨é‡Šè¯´æ˜**
2. ç»“åˆå¤´æ–‡ä»¶ä¸­çš„å·²æœ‰æ³¨é‡Šå’Œå¤§æ¨¡å‹åˆ†æï¼Œç”Ÿæˆå®Œæ•´çš„å‡½æ•°è¯´æ˜
3. å¦‚æœå¤´æ–‡ä»¶ä¸­å·²æœ‰è¯¦ç»†çš„æ³¨é‡Šè¯´æ˜ï¼Œå°½é‡ä¿ç•™åŸæ–‡å«ä¹‰
4. å°†å‡½æ•°æŒ‰ç…§åŠŸèƒ½åˆ†ç±»ï¼ˆå¦‚ï¼šé…ç½®ç›¸å…³ã€åˆå§‹åŒ–ä¸æ¸…ç†ã€æ ¸å¿ƒåŠŸèƒ½ã€è¾…åŠ©åŠŸèƒ½ç­‰ï¼‰
5. æ¯ä¸ªåˆ†ç±»ä½¿ç”¨ä¸‰çº§æ ‡é¢˜ï¼ˆ###ï¼‰
6. æ¯ä¸ªå‡½æ•°ä½¿ç”¨å››çº§æ ‡é¢˜ï¼ˆ#### `function_name()`ï¼‰
7. åŠŸèƒ½æè¿°ç®€æ´æ˜äº†ï¼Œä¸€å¥è¯è¯´æ˜
8. å‚æ•°ä½¿ç”¨åˆ—è¡¨æ ¼å¼ï¼ˆ**å‚æ•°åç§°**: è¯´æ˜ï¼‰
9. è¿”å›å€¼æ¸…æ™°è¯´æ˜ï¼ˆæˆåŠŸ/å¤±è´¥åŠå…·ä½“å«ä¹‰ï¼‰
10. ç¤ºä¾‹ä»£ç å¿…é¡»çœŸå®ï¼Œä»æºä»£ç ä¸­æå–å®é™…è°ƒç”¨
11. åªåˆ†æincludeæ–‡ä»¶å¤¹ä¸‹çš„å¤´æ–‡ä»¶åŠå…¶å¯¹åº”çš„å®ç°
"""

    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹Cä»£ç çš„å‡½æ•°å®šä¹‰ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„å‡½æ•°è¯´æ˜æ–‡æ¡£ï¼š

{all_code[:15000]}
"""

    # è°ƒç”¨å¤§æ¨¡å‹
    from coze_coding_dev_sdk import LLMClient
    from langchain_core.messages import SystemMessage, HumanMessage

    client = LLMClient(ctx=ctx)
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt)
    ]

    response = client.invoke(
        messages=messages,
        model=llm_config.get("model", "doubao-seed-1-6-251015"),
        temperature=llm_config.get("temperature", 0.3),
        top_p=llm_config.get("top_p", 0.7),
        max_tokens=llm_config.get("max_tokens", 3000),
        frequency_penalty=llm_config.get("frequency_penalty", 0)
    )

    header_functions = response.content
    return ExtractFunctionsOutput(header_functions=header_functions)


def analyze_call_relation_node(state: AnalyzeCallRelationInput, config: RunnableConfig, runtime: Runtime[Context]) -> AnalyzeCallRelationOutput:
    """
    title: å‡½æ•°è°ƒç”¨å…³ç³»åˆ†æ
    desc: åˆ†æä»£ç ä¸­å‡½æ•°è°ƒç”¨çš„å±‚çº§å…³ç³»ï¼Œè¾“å‡ºç»„ä»¶çš„å¤„ç†æµç¨‹
    integrations: å¤§è¯­è¨€æ¨¡å‹
    """

    from coze_coding_dev_sdk import LLMClient
    from langchain_core.messages import SystemMessage, HumanMessage

    component_path = state.extracted_path
    ctx = runtime.context

    # è¯»å–é…ç½®æ–‡ä»¶
    cfg_file = os.path.join(os.getenv("COZE_WORKSPACE_PATH"), config['metadata']['llm_cfg'])
    with open(cfg_file, 'r') as fd:
        _cfg = json.load(fd)

    llm_config = _cfg.get("config", {})
    sp = _cfg.get("sp", "")
    up = _cfg.get("up", "")

    # æ”¶é›†æ‰€æœ‰ä»£ç æ–‡ä»¶å†…å®¹
    code_content = []
    for root, dirs, files in os.walk(component_path):
        for file in files:
            if file.endswith('.c') or file.endswith('.h'):
                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        relative_path = os.path.relpath(file_path, component_path)
                        # å¢åŠ ä»£ç é•¿åº¦é™åˆ¶ï¼Œä»¥ä¾¿æ›´å…¨é¢åœ°åˆ†æçº¿ç¨‹å‡½æ•°å†…å®¹
                        code_content.append(f"\n// File: {relative_path}\n{content[:5000]}\n")
                except Exception as e:
                    code_content.append(f"\n// Error reading {file_path}: {str(e)}\n")

    all_code = "\n".join(code_content)

    # ä½¿ç”¨jinja2æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
    up_tpl = Template(up)
    user_prompt_content = up_tpl.render({"code_content": all_code[:30000]})

    # è°ƒç”¨å¤§æ¨¡å‹åˆ†æå‡½æ•°è°ƒç”¨å…³ç³»
    from coze_coding_dev_sdk import LLMClient
    from langchain_core.messages import SystemMessage, HumanMessage

    client = LLMClient(ctx=ctx)
    messages = [
        SystemMessage(content=sp),
        HumanMessage(content=user_prompt_content)
    ]

    response = client.invoke(
        messages=messages,
        model=llm_config.get("model", "doubao-seed-1-6-251015"),
        temperature=llm_config.get("temperature", 0.3),
        top_p=llm_config.get("top_p", 0.7),
        max_tokens=llm_config.get("max_tokens", 2000),
        frequency_penalty=llm_config.get("frequency_penalty", 0)
    )

    call_relationship = response.content

    return AnalyzeCallRelationOutput(call_relationship=call_relationship)


def generate_flowchart_node(state: GenerateFlowchartInput, config: RunnableConfig, runtime: Runtime[Context]) -> GenerateFlowchartOutput:
    """
    title: æµç¨‹å›¾ç”Ÿæˆ
    desc: æ ¹æ®å‡½æ•°è°ƒç”¨å…³ç³»ç”Ÿæˆæ¸…æ™°çš„æµç¨‹å›¾ï¼ˆMermaidæ ¼å¼ï¼‰ï¼Œå¯æ‹†åˆ†ä¸ºå¤šä¸ªå°æµç¨‹å›¾
    integrations: å¤§è¯­è¨€æ¨¡å‹
    """

    from coze_coding_dev_sdk import LLMClient
    from langchain_core.messages import SystemMessage, HumanMessage

    ctx = runtime.context

    # è¯»å–é…ç½®æ–‡ä»¶
    cfg_file = os.path.join(os.getenv("COZE_WORKSPACE_PATH"), config['metadata']['llm_cfg'])
    with open(cfg_file, 'r') as fd:
        _cfg = json.load(fd)

    llm_config = _cfg.get("config", {})
    sp = _cfg.get("sp", "")
    up = _cfg.get("up", "")

    # ä½¿ç”¨jinja2æ¨¡æ¿æ¸²æŸ“æç¤ºè¯
    up_tpl = Template(up)
    user_prompt_content = up_tpl.render({"call_relationship": state.call_relationship})

    # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæµç¨‹å›¾
    client = LLMClient(ctx=ctx)
    messages = [
        SystemMessage(content=sp),
        HumanMessage(content=user_prompt_content)
    ]

    response = client.invoke(
        messages=messages,
        model=llm_config.get("model", "doubao-seed-1-6-251015"),
        temperature=llm_config.get("temperature", 0.3),
        top_p=llm_config.get("top_p", 0.7),
        max_tokens=llm_config.get("max_tokens", 2000),
        frequency_penalty=llm_config.get("frequency_penalty", 0)
    )

    flow_diagrams = response.content

    return GenerateFlowchartOutput(flow_diagrams=flow_diagrams)


def generate_readme_node(state: GenerateReadmeInput, config: RunnableConfig, runtime: Runtime[Context]) -> GenerateReadmeOutput:
    """
    title: READMEç”Ÿæˆ
    desc: æ•´åˆæ‰€æœ‰åˆ†æç»“æœï¼Œç”Ÿæˆç¾åŒ–çš„Markdownæ ¼å¼README.mdæ–‡æ¡£
    """

    # è·å–ç»„ä»¶åç§°
    component_name = state.component_name if hasattr(state, 'component_name') and state.component_name else "ç»„ä»¶"

    # å¤„ç†æ–‡ä»¶å¤¹ç»“æ„ï¼Œæ›¿æ¢ä¸´æ—¶ç›®å½•åä¸ºç»„ä»¶åç§°
    folder_structure = state.folder_structure
    # æ›¿æ¢ä¸´æ—¶ç›®å½•åï¼ˆå¦‚component_extracted_xxxxxxï¼‰ä¸ºç»„ä»¶åç§°
    import re
    temp_dir_pattern = r'component_extracted_[a-zA-Z0-9_]+'
    folder_structure = re.sub(temp_dir_pattern, component_name, folder_structure)

    # ä»æ–‡ä»¶å¤¹ç»“æ„ä¸­æå–ä¸»è¦æ¨¡å—
    def extract_main_modules(folder_structure):
        """ä»æ–‡ä»¶å¤¹ç»“æ„ä¸­æå–ä¸»è¦æ¨¡å—"""
        modules = []
        # æŸ¥æ‰¾å¸¸è§çš„ç›®å½•åç§°
        common_dirs = [
            r'(\w+)/\s*#\s*(å…¬å…±|API|å¤´æ–‡ä»¶)',
            r'(\w+)/\s*#\s*(å®ç°|æºæ–‡ä»¶)',
            r'(\w+)/\s*#\s*(ç¬¬ä¸‰æ–¹|vendor|ä¾èµ–)',
            r'(\w+)/\s*#\s*(æ¨¡å‹|model)',
            r'(\w+)/\s*#\s*(æ•°æ®|data)',
            r'(\w+)/\s*#\s*(å·¥å…·|tool)',
            r'(\w+)/\s*#\s*(æ–‡æ¡£|doc)',
            r'(\w+)/\s*#\s*(æµ‹è¯•|test)',
        ]
        for pattern in common_dirs:
            matches = re.findall(pattern, folder_structure)
            for match in matches:
                if isinstance(match, tuple):
                    modules.append(match[0])
                else:
                    modules.append(match)
        # å»é‡å¹¶è¿”å›å‰5ä¸ª
        return list(set(modules))[:5]

    main_modules = extract_main_modules(folder_structure)

    # ä»å‡½æ•°è°ƒç”¨å…³ç³»ä¸­æå–å…³é”®åŠŸèƒ½
    def extract_key_functions(call_relationship):
        """ä»å‡½æ•°è°ƒç”¨å…³ç³»ä¸­æå–å…³é”®åŠŸèƒ½"""
        key_functions = []
        # æŸ¥æ‰¾å…³é”®é˜¶æ®µ
        patterns = [
            r'åˆå§‹åŒ–.*?[:ï¼š](.*?)(?:\n|$)',
            r'è§†é¢‘.*?[:ï¼š](.*?)(?:\n|$)',
            r'éŸ³é¢‘.*?[:ï¼š](.*?)(?:\n|$)',
            r'é‡‡æ ·çº¿ç¨‹.*?[:ï¼š](.*?)(?:\n|$)',
            r'æ£€æµ‹çº¿ç¨‹.*?[:ï¼š](.*?)(?:\n|$)',
            r'object_detector.*?[:ï¼š](.*?)(?:\n|$)',
        ]
        for pattern in patterns:
            matches = re.findall(pattern, call_relationship, re.MULTILINE)
            for match in matches:
                if match and len(match) > 0:
                    clean_match = match.strip()[:50]  # é™åˆ¶é•¿åº¦
                    if clean_match:
                        key_functions.append(clean_match)
        # å»é‡å¹¶è¿”å›å‰5ä¸ª
        return list(set(key_functions))[:5]

    key_functions = extract_key_functions(state.call_relationship)

    # ä»æµç¨‹å›¾ä¸­æå–ä¸»è¦æµç¨‹
    def extract_main_flow(flow_diagrams):
        """ä»æµç¨‹å›¾ä¸­æå–ä¸»è¦æµç¨‹"""
        flows = []
        # æŸ¥æ‰¾ä¸»è¦èŠ‚ç‚¹
        patterns = [
            r'\[([^]]+åˆå§‹åŒ–[^]]*)\]',
            r'\[([^]]+çº¿ç¨‹[^]]*)\]',
            r'\[([^]]+å¤„ç†[^]]*)\]',
        ]
        for pattern in patterns:
            matches = re.findall(pattern, flow_diagrams)
            for match in matches:
                if match:
                    flows.append(match[:30])  # é™åˆ¶é•¿åº¦
        # å»é‡å¹¶è¿”å›å‰5ä¸ª
        return list(set(flows))[:5]

    main_flows = extract_main_flow(state.flow_diagrams)

    # ç”Ÿæˆç®€ä»‹
    introduction = f"""{component_name}æ¨¡å—æ˜¯ä¸€ä¸ªåŸºäºCè¯­è¨€å¼€å‘çš„ç»„ä»¶ï¼Œæœ¬æ–‡æ¡£ç”±ä»£ç åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆã€‚

### åŠŸèƒ½æ¦‚è¿°
æœ¬ç»„ä»¶æä¾›äº†å®Œæ•´çš„Cè¯­è¨€APIæ¥å£ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š"""

    # æ·»åŠ å…³é”®åŠŸèƒ½
    if key_functions:
        for func in key_functions:
            introduction += f"\n- {func}"
    else:
        introduction += "\n- æ ¸å¿ƒåŠŸèƒ½å¤„ç†"
        introduction += "\n- æ¨¡å—åŒ–æ¥å£è®¾è®¡"

    # æ·»åŠ ä¸»è¦æ¨¡å—
    if main_modules:
        introduction += "\n\n### ä¸»è¦æ¨¡å—\næœ¬ç»„ä»¶åŒ…å«ä»¥ä¸‹ä¸»è¦æ¨¡å—ï¼š"
        for module in main_modules:
            introduction += f"\n- `{module}`"

    # æ·»åŠ ä¸»è¦æµç¨‹
    if main_flows:
        introduction += "\n\n### æ ¸å¿ƒæµç¨‹\nç»„ä»¶çš„ä¸»è¦å¤„ç†æµç¨‹åŒ…æ‹¬ï¼š"
        for flow in main_flows:
            introduction += f"\n- {flow}"

    introduction += f"""

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†ç»„ä»¶çš„ç›®å½•ç»“æ„ã€APIæ¥å£ã€å‡½æ•°è°ƒç”¨å…³ç³»å’Œæ‰§è¡Œæµç¨‹ï¼Œå¸®åŠ©å¼€å‘è€…å¿«é€Ÿç†è§£å’Œä½¿ç”¨è¯¥ç»„ä»¶ã€‚"""

    # ä½¿ç”¨ç¾åŒ–çš„Markdownæ ¼å¼ï¼Œå‚è€ƒé™„ä»¶æ ¼å¼
    readme_content = f"""# {component_name} æ¨¡å—

## ç®€ä»‹

{introduction}

## ç›®å½•ç»“æ„

{folder_structure}

## API å‚è€ƒ

{state.header_functions}

## å‡½æ•°è°ƒç”¨å…³ç³»

{state.call_relationship}

## å¤„ç†æµç¨‹å›¾

```mermaid
{state.flow_diagrams}
```

---

*æ–‡æ¡£ç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    return GenerateReadmeOutput(readme_content=readme_content)
